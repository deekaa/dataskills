---
title: "Data skills für Sozialarbeiter:innen"
author: "Dorian Kessler and Samin Sepahniya"
date: !r Juni 2024
output:
  html_document:
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '4'
editor_options: 
  markdown: 
    wrap: 72
---

```{=html}
<style type="text/css">
h1 { font-size: 140%; }
h2 { font-size: 130%; }
h3 { font-size: 120%; }
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = TRUE)
```

# Crash Course in R

## Working Directory, Objects, and Workspace

-   **Working Directory**
    -   `getwd()`: Displays the working directory.
    -   `setwd()`: Defines a new working directory.
    -   `dir()`: Displays the contents of the current working directory.
    -   **Do not use `\` for path specifications, use `/` or `\\` instead.**
-   **Objects**
    -   "Naming guidelines": meaningful names; no spaces; start with a letter.
    -   `a <- 10` or `a = 10`: Creates or overwrites the object `a` with the content on the right (10).
    -   `a`: Displays the content of the object `a`.
    -   `rm()`: Deletes objects from the workspace.
    -   `save(a, b, file = "example.RData")`: Saves the specified objects (a, b) in the current working directory.
    -   `load("example.RData")`: Loads all objects saved in the specified file.
    -   `#`: Starts a commented line that is not interpreted.
-   **Workspace**
    -   Here are all the objects that have been worked with.
    -   If the workspace was saved when closing (R asks for it), it will be loaded again when R starts.
    -   `ls()`: Displays all objects in the current workspace.
    -   The workspace is saved in the current working directory by default.

## Example: Working Directory, Objects, and Workspace

```{r Example: Working Directory, echo=T, eval=F}
# Comments start with #
# Everything in the line after # is ignored by R
5+5

getwd() # Display working directory
# Define your working directory
setwd("S:/MA1082973/_FHNW/BA472/R/dataskills") 

dir() # Display working directory

a <- 50 # Creates object a (number vector of length 1) with the single value 50
a

# With c() - concatenate you can also build a number vector with several elements:
b <- c(1, 2, 3, 4)

# or shorter
b <- seq(1,4)

# or even shorter
b <- 1:4

# Create object containing the first names of the Beatles
the.beatles <- c("John", "Paul", "George", "Ringo") 
the.beatles # compared to a, the object is now a string/character


# Object names must not have spaces. It is also recommended - and _ should be avoided (Google R Style Guide)
# Names should be meaningful. Naming should be consistent throughout the code file (dots, upper/lower case)

ls() # Display workspace
rm(die.beatles) # Delete object

```

## Arithmetic and logical operators

### Example: Calculating and comparing

```{r Example:Rechnen und Vergleichen, eval=FALSE}
# Calculate
result <- (23+24)*11/(18+15)*5
result

# Functions
log(2) 
cos(2)

# Comparison
x <- -3:3
x

# Are the elements of x equal to 0?
x == 0

# greater than 0?
x > 0

# less than 0?
x < 0

# greater than or equal to 0?
x >= 0

# less than or equal to 0?
x <= 0

# not equal to 0?
x != 0

# greater than -1 but less than 1
x > -1 & x < 1

# greater than 1 and less than -1
x > 1 & x < -1

# greater than 1 or less than -1
x > 1 | x < -1
```

### Exercise: Calculating and comparing

1.  calculate the following terms in R
    1.  $((3 + 4 - 5) - 9)^{2}$
    2.  $\sqrt{20}$
2.  check the following comparisons:
    1.  $5 = 7$
    2.  $\sqrt{3} \neq cos(17)$

### Solution: Calculating and comparing

```{r Solution: Rechnen und Vergleichen, echo=TRUE, eval=FALSE}
# 1.
((3+4-5)-9)^2
sqrt(20)

# 2.
5==7
sqrt(3)!=cos(17)
```

## Class / data types

### Overview of data types

```{r Übersicht Datentypen, eval=F}
# Integer vector
x <- c(1, 2, 3)
class(x)
x

# String/character vector
x <- c("a", "b", "c")
class(x)
x

# factors
sex <- c(0, 0, 1, 1)
factor(sex, labels=c("man", "woman"))

# Functions: e.g. mean(), sd()
class(mean)
mean

```

### Special values

-   `Inf` and `-Inf`: Positive and negative infinite
-   `NaN`: "*Not a number*", e.g. `0/0`.
-   `NA`: missing value (Missing)

```{r Sonderwerte, eval=FALSE}
# Important note on missing values:
x <- c(1, 2, NA, 4)

#wrong:
x == NA
x == "NA"

#correct:
is.na(x)
```

### Data Frames

#### Example: Data Frames

```{r Data frames, eval=FALSE}
# Prepared data are often data frames.
richtungswechsel <- read.csv("S:/MA1082973/_FHNW/BA472/data sets/Richtungswechsel/Richtungswechsel_anonymized data set.csv")

class(richtungswechsel)

# you can also easily build one yourself
beruf <- c("Lehrerin", "Verkäufer", "Pilotin")
nation <- c("CH", "DE", "IT")
id <- 1:3
df <- data.frame(id, beruf, nation)
df

# Addressing rows and column positions
df$nation # Variante 1: zeige mir die Spalte nation
df[, "nation"]  # Variante 3: zeige mir die Spalte nation
df[3, "beruf"] # zeige mir Zeile 3, Spalte Beruf
df[3, 3]       # zeige mir Zeile 3 und Spalte 3 --> Eselsbrücke: Zeilen zuerst, Spalten spaeter

```

#### Exercise: Import data

-   Read the data set `Naturprojekt`, `Richtungswechsel` and `FokusArbeit` into R. You can use this command: *read_sav("your workingdirectory/data_Naturprojekt.sav")* in *haven* package to read SPSS data and this command: *read.csv("your workingdirectory/Richtungswechsel_anonymized data set.csv")* for csv data.

-   Look at the data structure and the variables of the data set. Also use functions such as: `summary(dataset$var)`, `head(dataset)`, `names(dataset)`

#### Solution: Import data

```{r Solution: shp data, echo=TRUE, eval=FALSE}
# load libraries 
library(haven)

# read Naturprojekt data
Naturdata <- read_sav("S:/MA1082973/_FHNW/BA472/data sets/Naturprojekt/cleandata_naturproj_BA472.sav")

# data structure
head(Naturdata)
names(Naturdata)
summary(Naturdata)

# read richtungswechsel data
richtungswechsel <- read.csv("S:/MA1082973/_FHNW/BA472/data sets/Richtungswechsel/Richtungswechsel_anonymized data set.csv")

names(richtungswechsel)
summary(richtungswechsel)

# read FokusArbeit data
FokusAbl <- read.csv("S:/MA1082973/_FHNW/BA472/data sets/Fokus Arbeit/FokusArbeit_Abloesung.csv")

FokusWirk <- read.csv("S:/MA1082973/_FHNW/BA472/data sets/Fokus Arbeit/FokusArbeit_Wirkung.csv")

names(FokusAbl)
summary(FokusAbl)
```

## Data management

### Tidy vs. Messy Data

-   some conventions for the clean presentation/storage of data (Hadley Wickham)
-   see <http://vita.had.co.nz/papers/tidy-data.pdf> and <http://tidyverse.org/>
-   Quintessence:
    -   once data is clean (tidy), analysis tools (plotting, model fitting) can also work cleanly and without additional effort (e.g. ggplot2, lm/glm)
    -   Cases (observation units) in rows, variables (observation dimensions) in columns
-   Data is messy if
    -   Columns are not labeled
    -   A column contains more than one variable
    -   variables also appear in rows instead of columns
    -   different observation units are in the same table
-   Tools to clean data (small selection):
    -   `dplyr` / `data.table`
    -   `melt() dcast()` from `reshape2`
    -   `str_replace()`, `str_sub()` from the `stringr` package
    -   `tolower()`
    -   some more in package `tidyr`
    -   also useful: `recode()` from John Fox (package `car`)

#### Example: Tidy vs Messy Data

```{r Example: Tidy vs Messy Data, eval=FALSE}
# Wetterdaten
weather <- read.table("https://raw.githubusercontent.com/justmarkham/tidy-data/master/data/weather.txt", header=TRUE)
head(weather) # the variables are in rows and columns 

# reshape the data (melt) and delete mssings values
library(reshape2) # for melt()/dcast()
weather1 <- melt(weather, id=c("id", "year", "month", "element"), na.rm=TRUE)
head(weather1)

# clean column for "day"
library(stringr)    # for str_replace(), str_sub()
weather1$day <- as.integer(str_replace(weather1$variable, "d", ""))

# we do not need the "variable" column
weather1$variable <- NULL

# The element column contains two different variables tmin and tmax. 
# These should be in two columns:
weather1$element <- tolower(weather1$element) # lowercase letters
weather.tidy <- dcast(weather1, ... ~ element) # reshapen to two columns
head(weather.tidy)

# the date can also be displayed in a column as a real date:
weather.tidy$date <- as.Date(paste(weather.tidy$year, 
                                   weather.tidy$month, 
                                   weather.tidy$day, sep="-"))
weather.tidy[, c("year", "month", "day")] <- NULL
head(weather.tidy)
```

# Descriptive statistics

An example for illustration

```{r rw example, eval=FALSE}
# Example: Clean data & Exploration
# Data: Richtungswechsel 
# Goal: Create a descriptive table for Participant Characteristics (N=106) & a graph to visualize the change in earnings

#load packages
library(dplyr)
# install.packages("huxtable") 
library(huxtable)
library(ggplot2)

# set working directory
setwd("S:/MA1082973/_FHNW/BA472")

#load data
richtungswechsel <- read.csv("S:/MA1082973/_FHNW/BA472/data sets/Richtungswechsel/Richtungswechsel_anonymized data set.csv")

# Exploration
summary(richtungswechsel)
View(richtungswechsel)
names(richtungswechsel)
mean(richtungswechsel$Alter)
sd(richtungswechsel$Alter)
table(richtungswechsel$Geschlecht)

boxplot(richtungswechsel$Bezugsdauer)

# Create a new data set with the variables I am interested in
sub_rw <- richtungswechsel %>% filter(source != "Dropout") %>%
  select(Alter, Geschlecht, Bezugsdauer, Staatsang., EINA1, EINA2, earnings.change, INT1)
# 
sub_rw <- sub_rw %>% mutate(Geschlecht=ifelse(Geschlecht==1, "Female", "Male"),
                            # create age groups for the descriptive table
                            Age_groups=ifelse(Alter<35, "25–34 years",
                                              ifelse(Alter>34 & Alter<45, "35–44 years",
                                                     ifelse(Alter>44 & Alter<55, "45–54 years",
                                                            ifelse(Alter>54 & Alter<65, "55–64 years",
                                                                   NA)))))

geschl_tab <- as.data.frame(table(sub_rw$Geschlecht))
Age_tab <- as.data.frame(table(sub_rw$Age_groups))

# combine the dataframes for gender and age
combined_df <- data.frame(
  Variable = c("Gender", as.character(geschl_tab$Var1), "Age",as.character(Age_tab$Var1)),
  n = c("", geschl_tab$Freq, "", Age_tab$Freq),
  percent = c("", geschl_tab$Freq/106*100, "", Age_tab$Freq/106*100)
)

# Create and format the huxtable
deskriptive_tabelle1 <- hux(combined_df) %>%
  # Set all borders to have a width of 1 (adds borders around all cells)
  set_all_borders(1) %>%  
  # Set a caption for the table
  set_caption("Participant Characteristics (N=81)") %>%   
  # Make the first, second and fifth row bold 
  set_bold(c(1, 2, 5), TRUE)  

# save the table in docx document
quick_docx(deskriptive_tabelle1, file = "R/results/desc_tab1.docx")

# Part 2: Descriptive statistics: Calculate mean & standard deviation
tab1 <- sub_rw %>%
  summarise(
    Alter_mean = mean(Alter, na.rm = TRUE),
    Alter_sd = sd(Alter, na.rm = TRUE),
    Bezugsdauer_mean = mean(Bezugsdauer, na.rm = TRUE),
    Bezugsdauer_sd = sd(Bezugsdauer, na.rm = TRUE),
    earnings_change_mean = mean(earnings.change, na.rm = TRUE),
    earnings_change_sd = sd(earnings.change, na.rm = TRUE)
  )

# create a data set in long format for huxtable
tab_long <- data.frame(
  Variable = c("Age (in years)", "Social assistance receipt (in years)", "Earnings Change (in CHF)"),
  Mean = c(tab1$Alter_mean, tab1$Bezugsdauer_mean, tab1$earnings_change_mean),
  SD = c(tab1$Alter_sd, tab1$Bezugsdauer_sd, tab1$earnings_change_sd)
)

# Create and format the huxtable 
deskriptive_tabelle2 <- hux(tab_long) %>%
  set_all_borders(1) %>%
  set_caption("Descriptive table") %>%
  set_bold(1, TRUE) 

# Save desciptive table part 2
quick_docx(deskriptive_tabelle2, file = "R/results/desc_tab2.docx")
```

## Contingency tables

-   `table(x)`: one-dimensional contingency table
-   `table(x,y)`: two-dimensional contingency table
-   `prop.table(table(x))`: relative frequency

### Example: Contingency tables

```{r Kontingenztabellen, eval=FALSE}
# Let's define a new variable AGE that contains the age (in years) of ten people.
age <- c(76, 54, 38, 96, 32, 76, 81, 81, 50, 75)

# Let's take hosp to be a variable that contains the information if the same ten persons have been hospitalized in the last six months (1= yes, 0 = no)
hosp <- c(1, 0, 0, 0, 0, 1, 0, 0, 1, 0)

# Tabelle
table(age)
table(age, hosp)

# Tabelle in Prozent
100*prop.table(table(age))
100*prop.table(table(age, hosp))

```

## Univariate statistics (1 variable)

-   `mean(x)`: Mean
-   `sd(x)`: Standard deviation
-   `var(x)`: Variance
-   `median(x)`: Median
-   `min(x)`: minimum
-   `max(x)`: Maximum

```{r univariate, eval=FALSE}
# Mean
mean(age)
sd(age)

# Median
median(age) 
sort(age)

# Funktion summary
summary(age)
```

## Package dplyr

-   package [dplyr](http://blog.rstudio.org/2014/01/17/introducing-dplyr/) by [Hadley Wickham](https://twitter.com/hadleywickham)/[Romain Francois](https://twitter.com/romain_francois) offers a toolset for data preparation
-   See [the dplyr vignette](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) and the [Data Wrangling Cheat Sheet](http://www.rstudio.com/resources/cheatsheets/) for a very good overview
    -   `filter()`: selects a subset of rows (see also `slice()`)
    -   `arrange()`: sorts
    -   `select()`: selects columns
    -   `mutate()`: creates new columns
    -   `summarize()`: aggregates (collapses) data to individual data points
    -   `distinct()`: removes duplicate values
    -   `group_by()`: defines subgroups in the data so that `mutate()` and `summarize()` can be applied separately per group.
    -   dplyr can be used very well together with so-called piping, i.e. the data object is passed from function to function by `%>%`, which makes the code much easier to read and more compact.

### Example: Package dplyr

```{r Example: Package dplyr,eval=FALSE}
# load libraries
library(dplyr)
library(haven)

# read Naturprojekt data
Naturdata <- read_sav("S:/MA1082973/_FHNW/BA472/data sets/Naturprojekt/cleandata_naturproj_BA472.sav")

# filter by living place "stadt" & kids older than 11
# select columns
# Variant 1
stadtdata <- filter(Naturdata, stadt == 1, age_kid > 11)
stadtdata <- select(stadtdata, c("maedchen", "schulweg_zufuss", "schulweg_velo", "schulweg_oev", "schulweg_auto"))

# or (variant 2)
stadtdata2 <- Naturdata %>% filter(stadt == 1, age_kid > 11) %>% select(c("maedchen","schulweg_zufuss", "schulweg_velo", "schulweg_oev", "schulweg_auto"))

# create new variable "schulweg_aktiv"
stadtdata <- mutate(stadtdata, schulweg_aktiv = ifelse((schulweg_zufuss==1|schulweg_velo==1), 1, 0)) 

# Count by gender and schulweg_aktiv
tab <- stadtdata %>%
  group_by(maedchen, schulweg_aktiv) %>% 
  summarise(count = n()) %>% # zählt die Anzahl der Einträge in jeder Gruppe.
  na.omit() # Entfernt Zeilen mit fehlenden Werten.
```

### Exercise: Package dplyr

-   Read the Naturprojekt data into RStudio.

-   Restrict the data set for the families not living in the city (use `filter` function). Familiarize yourself a little with the data (e.g. `head()`, `summary()`, `table()`).

-   Look at the variables with the information on child's age (`age_kid`), living in countryside (`land`), quality of life (`LQ`) and the time spending outside (`draussen_zeit`) and high socioeconomic status (`SES_h`).

-   Create a crosstab with the variables `SES_h` and `land`.

-   calculate mean and standard deviation for the variable age for girls and boys.

### Solution: Package dplyr

```{r Solution: Package dplyr, eval=FALSE, echo=FALSE}
### read data 
library(haven)
library(dplyr)

Naturdata <- read_sav("S:/MA1082973/_FHNW/BA472/data sets/Naturprojekt/cleandata_naturproj_BA472.sav")

# filter by living place ""stadt" "not city"
mydata <- filter(Naturdata, stadt != 1)

# select columns
mydata <- select(mydata, c("age_kid", "maedchen", "land", "LQ", "draussen_zeit", "SES_h"))

summary(mydata)

table(mydata$age_kid)
table(mydata$maedchen)
table(mydata$land)
table(mydata$LQ)
table(mydata$draussen_zeit)
table(mydata$SES_h)

# Create a crosstab with the variables SES_h and land
table(mydata$SES_h, mydata$land)

# calculate mean and standard deviation for the variable age for girls and boys.
mydata_girls <- filter(mydata, maedchen==1)
mydata_boys <- filter(mydata, maedchen==0)

mean(mydata_girls$age_kid, na.rm=T)
mean(mydata_boys$age_kid, na.rm=T)

sd(mydata_girls$age_kid, na.rm=T)
sd(mydata_boys$age_kid, na.rm=T)

```

## Bivariate statistics (2 variables)

-   `cov()`: covariance
-   `cor()`: Correlation
-   `cor(x,y,method="spearman")`: Rank correlation
-   `?cor`: more information in the helpfile
-   `chisq.test()`: Chi-square test
-   `t.test()`: t-test

# Data visualization

## Visualization with ggplot2

-   ggplot2 is the most important package to create visualizations in R
-   see also cheatsheet: <https://rstudio.github.io/cheatsheets/data-visualization.pdf>

Hadley Wickham's `ggplot2` package has developed into a particularly useful alternative to `plot()` over the last few years. Especially complicated plots are easier to implement with ggplot, visually appealing and the code is easily accessible. Most important basic structures:

-   **Data** that we want to visualize

-   **Geometries** to define the shapes we want to use for visualization (e.g. a scatter plot, line chart, bar chart)

-   Modify **aesthetics** to convey different meanings (e.g. colors, size, thickness of a line)

-   Define **mappings** between geometries and aesthetics (e.g. how big should the data points be)

### Example: ggplot2

```{r Example: ggplot2, eval=FALSE}
library(ggplot2)
library(dplyr)
library(haven)

# load data
Naturdata <- read_sav("S:/MA1082973/_FHNW/BA472/data sets/Naturprojekt/cleandata_naturproj_BA472.sav")

# Scatterplot 
mydata <- Naturdata %>% select(LQ, SES, land, draussen_zeit) 

ggplot(data=mydata, aes(x = SES, y =LQ)) +
  geom_point() +
  labs(title = "Quality of life & Socioeconomic status",
       x = "SES",
       y = "LQ")

#
ggplot(data=mydata, aes(x = SES, y =LQ, color=factor(land))) +
  geom_point() +
  labs(title = "Streudiagramm",
       x = "SES",
       y = "LQ",
       color = "Wohnumgebung") +
  scale_color_manual(values=c("darkblue", "lightgreen"),
                    labels=c("nicht ländlich", "ländlich"))

# Erstelle ein Säulendiagramm
# Entfernen der NA-Werte für Variable SES und draussen_zeit
mydata <- mydata %>% filter(!is.na(SES) & !is.na(draussen_zeit)) 

ggplot(mydata, aes(x=factor(draussen_zeit), y=..count.., fill=factor(land))) +
  geom_bar(stat="count", position="dodge") +
  labs(x="Verbrachte Zeit draussen", y="Anzahl Stunden/Woche", fill="Wohnumgebung") +
  scale_fill_manual(values=c("darkblue", "lightgreen"), #Beschriftung für Legende
                    labels=c("nicht ländlich", "ländlich")) +
  ggtitle("Wie viel Zeit verbringt Ihr Kind normalerweise in einer Woche draussen in der Natur?")
```

### Exercise: Grafiken mit ggplot2

1.  Load the Naturproject data.
2.  Create a histogram for income (variable: inc_level). give the graph a title. Tip: Add a `labs()` argument to the chart.
3.  Create a scatterplot for quality of life (`LQ`) and time spending outside (`draussen_zeit`).

### Solution: Grafiken mit ggplot2

```{r Solution: Grafiken mit ggplot2, eval=FALSE, echo=FALSE}
# 1. Laden Sie die Naturprojekt Daten.
library(ggplot2)
library(dplyr)

mydata <- Naturdata%>%select(inc_level, LQ, draussen_zeit) # wähle die Spalten, die ich brauche

# 2. Erstellen Sie ein Histogram für das Einkommen der Eltern.
ggplot(mydata, aes(x=inc_level))+
     geom_histogram()+
     labs(title="Histogramm zum Einkommens")

# 3. Erstellen Sie ein Streudiagramm / Scatterplot mit LQ and time spending outside

ggplot(data=mydata, aes(x = draussen_zeit, y = LQ)) +
  geom_point() +
  labs(title = "Zusammenhang zwischen der verbrachten Zeit im Freien und der Lebensqualität",
    x = "Verbrachte Zeit im Freien (Stunden/Woche)",
    y = "Lebensqualitätsbewertung")
```

## Shiny Apps: General Information

-   [Shiny apps](https://shiny.rstudio.com/gallery/) are reactive web applications that allow users to modify components of a calculation and/or its visualization without needing to write R code themselves. This is very useful for communicating results.
-   Shiny apps consist of a website (user interface) and a computer running R (R-server): `Input()` from the user goes to the R-server, and the R-server sends `Output()` back.
-   Basic structure: R script (named app.R) containing
    -   `library(shiny)`
    -   `ui<-fluidPage()` with input and output functions. Possible input and output functions can be found [here](https://shiny.rstudio.com/reference/shiny/1.0.5/)
    -   `server<-function(input,output){}`
    -   `shinyApp(ui= ui, server=server)` (if ui and server are in one script)
-   [The R-Studio introduction to Shiny](https://shiny.rstudio.com/tutorial/)
-   R-Studio offers various [solutions](https://www.rstudio.com/products/shiny/shiny-server/) for deploying Shiny apps online (free: Shiny Server Open Source, Shinyapps.io)

### Example: Package shiny

```{r shiny, eval=FALSE, echo=TRUE}
# Ensure shiny and ggplot2 are installed
# install.packages("shiny")
# install.packages("ggplot2")

library(shiny)
library(ggplot2)

# Example data: a simple dataset related to social work
data <- data.frame(
  age = sample(18:65, 100, replace = TRUE), # Ages between 18 and 65
  satisfaction = sample(1:10, 100, replace = TRUE) # Satisfaction levels from 1 to 10
)

# Define the UI
ui <- fluidPage(
  titlePanel("Data Visualization for Social Work"),
  sidebarLayout(
    sidebarPanel(
      sliderInput("ageRange", 
                  "Select Age Range:", 
                  min = min(data$age), 
                  max = max(data$age), 
                  value = c(25, 40)),
      sliderInput("satisfactionRange", 
                  "Select Satisfaction with services range:", 
                  min = min(data$satisfaction), 
                  max = max(data$satisfaction), 
                  value = c(4, 7))
    ),
    mainPanel(
      textOutput("countOutput"),
      plotOutput("ageDistributionPlot") # Add this line to output the plot
    )
  )
)

# Define server logic
server <- function(input, output) {
  filteredData <- reactive({
    data[data$age >= input$ageRange[1] & data$age <= input$ageRange[2] & 
           data$satisfaction >= input$satisfactionRange[1] & data$satisfaction <= input$satisfactionRange[2], ]
  })
  
  output$countOutput <- renderText({
    paste("Number of cases within selected range:", nrow(filteredData()))
  })
  
  output$ageDistributionPlot <- renderPlot({
    ggplot(filteredData(), aes(x = age)) +
      geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
      theme_minimal() +
      labs(title = "Age Distribution of Selected Cases",
           x = "Age",
           y = "Frequency")
  })
}

# Run the app
shinyApp(ui = ui, server = server)
```

# Measuring the effects of social work

<!--# Time structure: why it is important to measure effects (9.30); counterfactual (Min 9.40); Excercise presentation (10.20-10.40); Data example (10.55-11.15); Data own excercise 11.15-11.50-->

## Why is it important to measure the effects of social work?

Improving practice with better knowledge

-   Understanding whether and how social work interventions and offers reach their goals (evaluation)

    -   Knowing the most effective interventions and offers

    -   Exercise

        -   [What conclusions would you draw from this paper for counseling clients thinking about gender affirmative surgey?](https://pubmed.ncbi.nlm.nih.gov/38699117/)

-   Legitimizing social work

    -   Gaining political support for social work

    -   Example:

        -   [Winterthur](https://www.buerobass.ch/fileadmin/Files/2021/2021_Reduktion_Falllast_Winterthur_Schlussbericht_DE.pdf)

-   Digitalization strongly facilitates measuring the effects of social work

    -   More outcome data (e.g. use of services)

    -   Easier randomization (e.g. changing formulations on a website to see whether it affects service usage)

## What is an effect and what not?

-   Effect = difference in the result with influencing variable versus without influencing variable (= **counterfactual** situation)

-   What is the **counterfactual** situation?

    -   The fictional world in which the influencing variable was not present.

<!-- -->

-   Exercise
    -   Talk to the person sitting next to you.
        -   What was the most important event in your life (family, education, work, health, social relationships)?
        -   What areas of your life have been affected by this event?
        -   What would these areas be like if the event had not happened (can you guess numbers)?
-   Example of effect measures in social work

[![](images/clipboard-851415407.png)](https://www.nber.org/papers/w30405)

-   Caution: "Wirkungsziele" are often not actual measures of "effects":

    -   [Federal Council guidelines for the labor market integration of persons with protection status S for cantons: 40% should have a job until the end of 2024](https://www.blick.ch/politik/40-prozent-sollen-stelle-haben-der-bundesrat-will-dass-mehr-ukrainerinnen-arbeiten-id19105587.html)
        -   Why does a canton (not) reaching the goal of 40% not say much about the effects of its measures?

## How can we measure the effects of social work with quantitative data?

### Asking experts

-   Asking individuals about the subjectively measured effect

-   Example: "On a scale from 0 to 10, how much does one daily glass of wine affect your health?"

-   Advantages

    -   Easy to measure: one question

    -   Subjective expertise: we know a lot about effects (e.g. pain killers)

-   Disadvantages

    -   We are unaware of the counterfactual

    -   Social desirability bias: we want to please the researcher

### Assessing correlations

-   Is there a systematic relationship between two dimensions?

-   Example: [wine consumption and dementia](https://pubmed.ncbi.nlm.nih.gov/9296132/)

-   Advantages

    -   Easy to measure: few questions
        -   Wine consumption
        -   Dementia symptoms

-   Disadvantages

    -   Often: correlation is not equal to causation
    -   Why do frequent wine drinkers show less dementia?

### Experiments - the gold standard

-   Gold standard: best way to measure effects

-   [Let's run an experiment](https://www.youtube.com/watch?v=hLhXCo2jQkg)

    -   Design

        -   2 (or more) randomly constituted groups

        -   one receives treatment, the other doesn't

        -   2 measurements: before versus after treatment

    [![](images/clipboard-1967496396.png)](https://www.researchgate.net/figure/Illustration-of-a-randomised-controlled-trial-RCT-to-test-a-new-back-to-work_fig2_256031307)

    -   Examples:

        -   [A helping hand goes a long way](https://www.nber.org/papers/w30405){.uri}

[![](images/clipboard-3712462696.png)](https://www.technologyreview.com/2020/12/10/1013914/pfizer-biontech-vaccine-chart-covid-19/)

-   **Advantages:**

    -   Secure statements on causality

    -   Control over treatment

-   **Disadvantages:**

    -   Ethical problems

    -   High financial and administrative burden

    -   Often limited generalizability

    -   Low variance (often only two manifestations: treatment vs. no treatment)

    -   Social desirability (except in double-blind studies with placebo)

### Natural experiments

-   A random event/dimension (Z) influences independent variable (X) but not the outcome (Y)

![](images/clipboard-739871177.png)

-   Examples

    -   [Unemployment insurance reform (Z), financial stress (X) and birth weight](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0264544) (Y)

    -   [Lockdowns in football stadiums (Z), racist climate (X) and black player performance (Y)](https://www.unil.ch/files/live/sites/de/files/working-papers/21.12.pdf)

    -   Effect of job application training

![](images/clipboard-106315684.png)

-   Advantages:

    -   Statements on causality (!)

    -   Practically relevant

    -   No distortion due to deliberate manipulation

-   **Disadvantages:**

    -   Limited samples: Reproducability?

    -   Randomness hard to prove

### Exercise

-   Form four groups: one for each method to measure effects

-   Imagine this: you want to find out how number of meetings with social worker affects client well-being

-   Please define a research design according to your method of effect measurement

    -   What data would you analyze?

    -   What numbers would you calculate to measure the effect?

## Analyzing social work experiments in R

### Example

```{r rct, echo=TRUE, eval=FALSE}

#We will analyze the effect of "Richtungswechsel" on long-term recipients' vitality. https://journals.sagepub.com/doi/full/10.1177/10497315241232120

#Download the data: with this command you can download files if you have the direct link to the file
download.file("https://drive.switch.ch/index.php/s/zpjX3z1frPOQKqr/download", "Richtungswechsel.R",mode = "wb")

#Because the file is in R-Data-Format (.R) we can load it directly
load("Richtungswechsel.R")

#To prepare the data for analysis and to analyze the data we will install/load the package "dplyr"
#install.packages("dplyr")
library(dplyr)

#Let's have a look at the Data
View(data.anonym)

#Are there missing values?

summary(data.anonym)

#Vit1 contains measures of vitality before Richtungswechsel, vit2 contains measures of vitality after Richtungswechsel

#We will give the data a nicer name
richtungswechsel <- data.anonym%>%
  filter(!is.na(vit2))%>%#We remove missing values
  mutate(vitality.change=vit2-vit1,#Here we calculate a new column measuring the change in vitality

         Group=ifelse(INT1==1,"Intervention group","Comparison group")) #Here ge give the variable INT1 (Group membership) a nicer, more telling name and labels
#Were there more positive changes in the intervention group?

#Here we check whether the two groups are comparable in terms of 

tabelle_wirkung<-richtungswechsel%>%
  group_by(Group)%>%#We tell R to do all calculations groupwise 
  summarise(Mean.Age=mean(Alter),
            Mean.Gender=mean(Geschlecht),
            Mean.Bezugsdauer=mean(Bezugsdauer))#We tell R to summarise all variabels in the data

#Here we calculate the effect of the intervetion
richtungswechsel%>%
  group_by(Group)%>%
  summarise(Mean.Change=mean(vitality.change),
            Mean.Vit1=mean(vit1,na.rm = T),
            Mean.Vit2=mean(vit2,na.rm=T)) #We tell R to calculate the mean value of the change in vitality. We must tell it to remove missing values.

#Was the effect stronger for men or for women?

richtungswechsel%>%
  group_by(Group,Geschlecht=ifelse(Geschlecht==1,"Women","Men"))%>%#We tell R to do all calculations groupwise 
  summarise(Mean.Change=mean(vitality.change,na.rm = T)) #We tell R to calculate the mean value of the change in vitality. We must tell it to remove missing values.


#Tabelle Wirkung abspeichern

library(huxtable)
# Konvertieren Sie die Tabelle in ein Huxtable-Objekt
tabelle_wirkung_hux <- as_hux(tabelle_wirkung)

# Erste Zeile fett und mit Linie abgrenzen
bold(tabelle_wirkung_hux)[1,] <- TRUE
bottom_border(tabelle_wirkung_hux)[1,] <- 1

# Erste Spalte fett formatieren
bold(tabelle_wirkung_hux)[,1] <- TRUE

# Speichern als Word-Dokument
quick_docx(tabelle_wirkung_hux, file = "tabelle_wirkung.docx")


```

### Excercise

-   Download data from [Fokus Arbeit](https://www.bfh.ch/de/forschung/forschungsprojekte/2021-557-302-115/). You can find it [here](https://drive.switch.ch/index.php/s/WYdxhZ0psZZqDzv).

-   Inspect data with respect to missing values and remove observations with missing values

-   Check the distribution of gender, duration of benefit receipt, age and vitality before the intervention in the intervention and the comparison group. Are the two groups comparable?

-   Calculate a new variable measuring the change in vitality before versus after the intervention.

-   Answer the following questions

    -   Are social assistance clients in Biel more vital than those participating in [Richtungswechsel](https://journals.sagepub.com/doi/full/10.1177/10497315241232120)?

    -   Did Fokus Arbeit increase vitality? Did it more so than in Richtungswechsel?

    -   Were the effects different by age, gender, duration of benefit receipt?

```{r rct2,eval=FALSE,echo=TRUE}

#We will analyze the effect of "Richtungswechsel" on long-term recipients' vitality. https://journals.sagepub.com/doi/full/10.1177/10497315241232120

#We will analyze the effect of "Richtungswechsel" on long-term recipients' vitality. https://journals.sagepub.com/doi/full/10.1177/10497315241232120

#Download the data: with this command you can download files if you have the direct link to the file
download.file("https://drive.switch.ch/index.php/s/zpjX3z1frPOQKqr/download", "Richtungswechsel.R",mode = "wb")

#Because the file is in R-Data-Format (.R) we can load it directly
load("Richtungswechsel.R")

#To prepare the data for analysis and to analyze the data we will install/load the package "dplyr"
#install.packages("dplyr")
library(dplyr)

#Let's have a look at the Data
View(data.anonym)

#Are there missing values?

summary(data.anonym)

#Vit1 contains measures of vitality before Richtungswechsel, vit2 contains measures of vitality after Richtungswechsel

#We will give the data a nicer name
richtungswechsel <- data.anonym%>%
  filter(!is.na(vit2))%>%#We remove missing values
  mutate(vitality.change=vit2-vit1,#Here we calculate a new column measuring the change in vitality
         
         Group=ifelse(INT1==1,"Intervention group","Comparison group")) #Here ge give the variable INT1 (Group membership) a nicer, more telling name and labels
#Were there more positive changes in the intervention group?

#Here we check whether the two groups are comparable in terms of 

richtungswechsel%>%
  group_by(Group)%>%#We tell R to do all calculations groupwise 
  summarise(Mean.Age=mean(Alter),
            Mean.Gender=mean(Geschlecht),
            Mean.Bezugsdauer=mean(Bezugsdauer))#We tell R to summarise all variabels in the data

#Here we calculate the effect of the intervetion
tabelle_wirkung<-richtungswechsel%>%
  group_by(Group)%>%
  summarise(Mean.Change=mean(vitality.change),
            Mean.Vit1=mean(vit1,na.rm = T),
            Mean.Vit2=mean(vit2,na.rm=T)) #We tell R to calculate the mean value of the change in vitality. We must tell it to remove missing values.

#Was the effect stronger for men or for women?

richtungswechsel%>%
  group_by(Group,Geschlecht=ifelse(Geschlecht==1,"Women","Men"))%>%#We tell R to do all calculations groupwise 
  summarise(Mean.Change=mean(vitality.change,na.rm = T)) #We tell R to calculate the mean value of the change in vitality. We must tell it to remove missing values.


#Tabelle Wirkung abspeichern
install.packages("huxtable")
library(huxtable)
# Konvertieren Sie die Tabelle in ein Huxtable-Objekt
tabelle_wirkung_hux <- as_hux(tabelle_wirkung)

# Erste Zeile fett und mit Linie abgrenzen
bold(tabelle_wirkung_hux)[1,] <- TRUE
bottom_border(tabelle_wirkung_hux)[1,] <- TRUE

# Erste Spalte fett formatieren
bold(tabelle_wirkung_hux)[,1] <- TRUE

# Speichern als Word-Dokument
quick_docx(tabelle_wirkung_hux, file = "tabelle_wirkung.docx")
```

## Important references

-   [Wirkungsevaluationen in der Sozialen Arbeit : ein Orientierungsbuch für die Praxis](https://digitalcollection.zhaw.ch/handle/11475/29971)

-   [Experimental Research Designs in Social Work: Theory and Applications](https://www.jstor.org/stable/10.7312/thye20116)

-   [The Power of Experiments](https://mitpress.mit.edu/9780262542272/the-power-of-experiments/)

# Prediction and AI in social work

<!--# Why? (9.30); How does it work? (9.45); Excercise (11); Own test (12) -->

## Why should we use machines to predict in social work?

-   Prediction is an integral part of individual-level social work

    -   It is used for **diagnosis**

        -   is about identifying clients' need for assistance

        -   The future developments of clients' without assistance is an integral part of diagnosis

        -   Based on predictions of future outcomes, we decide **which clients need our help most**

    -   It is also used for **treatment**

        -   When deciding on which action to take with our client (service, activity, intervention), we make predictions on [**which action will bring the greatest improvements?**](https://www.sciencedirect.com/science/article/pii/S0927537105000564)

-   On an aggregate level, we need to predict future need for services to ensure mobilization of adequate resources (i.e. asking for more funding)

    -   E.g. [expectations about case numbers in social assistance during covid](https://skos.ch/themen/sozialhilfe-und-corona/herausforderungen-fuer-das-soziale-system/)

-   Social workers, like all humans, make mistakes when predicting future developments, [although experienced social workers are more successful at it](https://academic.oup.com/bjsw/article-abstract/54/3/1150/7382101?redirectedFrom=fulltext).

-   Machines can help us predict outcomes more accurately, that's why we can call it artificial intelligence

    -   Helpfulness of machine predictions increase, the more data we have

## How do machine predictions work?

-   Basic technology: supervised machine learning

-   We need (a lot of) data about **outcomes** and **determinants** of these outcomes

    -   Supervised, because we tell the computer what the outcome and what the determinants are

-   Using prediction algorithms, the computer finds rules linking determinants to outcomes. These rule sets are a model.

-   There are simple and less simple prediction algorithms

    -   E.g., simple and rigid: Ordinary Least Squares

    -   E.g., complex and flexible: Neural Networks

        -   [Statquest for explanations of different algorithms](https://www.youtube.com/@statquest)

    -   In practice we often use [extreme gradient boosting](https://www.youtube.com/watch?v=OtD8wVaFm6E)

-   Model is used to predict unknown outcomes with information on predictors

-   It is more useful

    -   the more precise machines can predict the outcome

    -   the clearer it is what can be done to prevent the outcome

    -   the more important it is to intervene early

    -   the greater the difference between what at risk clients currently receive in terms of intervention and what they could receive

## Examples

-   Exercise

    -   Please choose one of the following texts on applications of prediction algorithms in fields related to social work

        -   [Berman et al. - 2024 - Trustworthy AI in the public sector An empirical .pdf](https://drive.switch.ch/index.php/s/0BnVw64Ld3IlHzl)

        -   [Black et al. - 2003 - Is the Threat of Reemployment Services More Effect.pdf](https://drive.switch.ch/index.php/s/x03olQjgxDtiZAl)

        -   [Gilholm et al. - 2023 - Machine learning to predict poor school performanc.pdf](https://drive.switch.ch/index.php/s/vQ0wcVhosqs8r0X)

        -   [Kleinberg et al. - 2018 - Human Decisions and Machine Predictions.pdf](https://drive.switch.ch/index.php/s/ukrf4MrRG4dejE2)

        -   [Rittenhouse et al. - 2023 - Algorithms, Humans and Racial Disparities in Child.pdf](https://drive.switch.ch/index.php/s/ziuaAdJWjWDU358)

        -   [Stevenson and Doleac - 2022 - Algorithmic Risk Assessment in the Hands of Humans.pdf](https://drive.switch.ch/index.php/s/fuogL1edjahkUSE)

        -   [Tennakoon et al. - 2023 - Using electronic health record data to predict fut.pdf](https://drive.switch.ch/index.php/s/yUkYmA5PtK8AvRY)

        -   [Toros and Flaming - 2018 - Prioritizing Homeless Assistance Using Predictive .pdf](https://drive.switch.ch/index.php/s/JRn0ybFpXYpaiLg)

    -   Answer the following questions (some questions may not be answered based on information in the papers):

        -   What decisions are to be taken based on AI output? Decision-support or decision-making?

        -   What data are used to train the models? What are the outcomes, what are the influencing factors?

        -   How accurate is it? More or less than humans or bureaucratic rules?

        -   How biased is it? More or less than humans or bureaucratic rules?

        -   Would humans trust and use it?

        -   What are the effects of usage?

## How to train your own prediction model

-   Training a prediction model involves the following steps

    -   Acquiring the data with past observations of determinants and outcomes

    -   Split observations into training data and test data

    -   Maximizing predictive performance

        -   Measures of predictive performance

            -   Continuous outcomes

                -   usually mean squared error

            -   Categorical outcomes

                -   correctly classified

        -   Play around with the choice of prediction algorithm

        -   For algorithms that have parameters: play around

```{r Prediction,eval=FALSE,echo=TRUE}
library(dplyr)

download.file("https://drive.switch.ch/index.php/s/hYUFQEOz12pFbvS/download", "FokusArbeit_Vorhersage.csv",mode = "wb")

#Because the file is in R-Data-Format (.R) we can load it directly
data <- read.csv("FokusArbeit_Vorhersage.csv")

#Lets have a look at the variables
names(data)

#Rename variables to make them more intuitive
data <- data %>%
  select(HasJob = Erwerbkorr.mean, # measures the proportion of months the client has a job in months 4 up to 24 after the intervention
         IsWoman = Weiblich, # Is a woman
         IsSwiss = Schweiz, # Is Swiss
         Speaks_language = Grundkompetenz.verstehen) %>% # Speaks either French/German
na.omit()

#Then we need to chose test Data and training data
# Set seed for reproducibility
set.seed(123)

# Calculate the number of rows for training data (80%)
train_rows <- sample(1:nrow(data), size = 0.8 * nrow(data))

# Split the data
train_data <- data %>% slice(train_rows)
test_data <- data %>% slice(-train_rows)

# Fit a linear model (Ordinary Least Squares)
model <- lm(HasJob ~ IsWoman + IsSwiss + Speaks_language, data = train_data)

#The advantage with OLS is that we can see which factors matter

# Predict on test data
predictions <- predict(model, newdata = test_data)

# Calculate Mean Squared Error (MSE)
mse <- mean((predictions - test_data$HasJob)^2)

# Print the results
cat("Mean Squared Error: ", mse)

```

## Exercise

-   Add in health (Gesund) and motivation (Arbeitsidentitaet) as predictors of labor market success. Which one is more important for predictive performance?

-   Can you predict more accurately when using the random forest algorithm than OLS?

-   Extra: Test your own predictive performance on a subset of 10 test observations. Can you predict better than the model? Use the following code to take the subset of the test data and make manual predictions.

    ```{r Prediction_excercisetip,eval=FALSE,echo=TRUE}
    # Test your own predictive performance on a subset of 10 test observations
    set.seed(123) # For reproducibility
    test_subset <- test_data %>% sample_n(10)

    # Display the subset to make manual predictions
    cat("\nTest Subset for Manual Prediction:\n")
    print(test_subset%>%select(-HasJob))

    # Manually input your predictions here
    manual_predictions <- c(40, 50, 30, 60, 20, 70, 40, 50, 30, 60)
    ```

```{r Prediction_Excercise, eval=FALSE,echo=FALSE}
library(dplyr)
library(randomForest)

# Download the data
download.file("https://drive.switch.ch/index.php/s/hYUFQEOz12pFbvS/download", "FokusArbeit_Vorhersage.csv", mode = "wb")

# Load the data
data <- read.csv("FokusArbeit_Vorhersage.csv")

# Rename variables to make them more intuitive
data <- data %>%
  select(HasJob = Erwerbkorr.mean, # measures the proportion of months the client has a job in months 4 up to 24 after the intervention
         IsWoman = Weiblich, # Is a woman
         IsSwiss = Schweiz, # Is Swiss
         Speaks_language = Grundkompetenz.verstehen, # Speaks either French/German
         Health = Gesund, # Health
         Motivation = Arbeitsidentitaet) %>% # Motivation
  na.omit()

# Set seed for reproducibility
set.seed(123)

# Calculate the number of rows for training data (80%)
train_rows <- sample(1:nrow(data), size = 0.8 * nrow(data))

# Split the data
train_data <- data %>% slice(train_rows)
test_data <- data %>% slice(-train_rows)

# Fit linear models with different sets of predictors
model_ols_basic <- lm(HasJob ~ IsWoman + IsSwiss + Speaks_language, data = train_data)
model_ols_health <- lm(HasJob ~ IsWoman + IsSwiss + Speaks_language + Health, data = train_data)
model_ols_motivation <- lm(HasJob ~ IsWoman + IsSwiss + Speaks_language + Motivation, data = train_data)
model_ols_full <- lm(HasJob ~ IsWoman + IsSwiss + Speaks_language + Health + Motivation, data = train_data)

# Predict on test data using OLS models
predictions_ols_basic <- predict(model_ols_basic, newdata = test_data)
predictions_ols_health <- predict(model_ols_health, newdata = test_data)
predictions_ols_motivation <- predict(model_ols_motivation, newdata = test_data)
predictions_ols_full <- predict(model_ols_full, newdata = test_data)

# Calculate Mean Squared Error (MSE) for OLS models
mse_ols_basic <- mean((predictions_ols_basic - test_data$HasJob)^2)
mse_ols_health <- mean((predictions_ols_health - test_data$HasJob)^2)
mse_ols_motivation <- mean((predictions_ols_motivation - test_data$HasJob)^2)
mse_ols_full <- mean((predictions_ols_full - test_data$HasJob)^2)

# Fit a Random Forest model with full predictors
model_rf <- randomForest(HasJob ~ IsWoman + IsSwiss + Speaks_language + Health + Motivation, data = train_data, ntree = 500)

# Predict on test data using Random Forest
predictions_rf <- predict(model_rf, newdata = test_data)

# Calculate Mean Squared Error (MSE) for Random Forest
mse_rf <- mean((predictions_rf - test_data$HasJob)^2)

# Print the results
cat("OLS Model - Basic Predictors (IsWoman, IsSwiss, Speaks_language):\n")
cat("Mean Squared Error: ", mse_ols_basic, "\n\n")

cat("OLS Model - Adding Health:\n")
cat("Mean Squared Error: ", mse_ols_health, "\n\n")

cat("OLS Model - Adding Motivation:\n")
cat("Mean Squared Error: ", mse_ols_motivation, "\n\n")

cat("OLS Model - Full Predictors (Including Health and Motivation):\n")
cat("Mean Squared Error: ", mse_ols_full, "\n\n")

cat("Random Forest Model - Full Predictors (Including Health and Motivation):\n")
cat("Mean Squared Error: ", mse_rf, "\n")


# Test your own predictive performance on a subset of 10 test observations
set.seed(123) # For reproducibility
test_subset <- test_data %>% sample_n(10)

# Display the subset to make manual predictions
cat("\nTest Subset for Manual Prediction:\n")
print(test_subset%>%select(-HasJob))
print(test_subset)
# Manually input your predictions here
# For example, let's assume you predicted the following:
manual_predictions <- c(40, 50, 30, 60, 20, 70, 40, 50, 30, 60)

# Calculate Mean Squared Error (MSE) for your manual predictions
mse_manual <- mean((manual_predictions - test_subset$HasJob)^2)

# Print your manual prediction results
cat("\nYour Manual Predictions:\n")
cat("Mean Squared Error: ", mse_manual, "\n")

```

## Important references

-   [Künstliche Intelligenz in der Sozialen Arbeit](https://link.springer.com/article/10.1007/s12054-022-00546-4)

-   [Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit: Eine exemplarische arbeitsfeldübergreifende Betrachtung des Natural Language Processing (NLP)](https://link.springer.com/10.1007/s12592-023-00455-7)

-   [Structuring the scattered literature onalgorithmic profiling in the case of unemployment through a systematicliterature review](https://www.emerald.com/insight/content/doi/10.1108/IJSSP-03-2022-0085/full/html?utm_source=TrendMD&utm_medium=cpc&utm_campaign=International_Journal_of_Sociology_and_Social_Policy_TrendMD_0&WT.mc_id=Emerald_TrendMD_0)

-   Video: [KI und Soziale Arbeit](https://open.vhb.org/blocks/ildmetaselect/detailpage.php?id=236#jgVhf9vzHvg)
